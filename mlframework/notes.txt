/* Pytorch */

/* Robotics */
    -- overview 
        * actuators (you apply force (e.g., torque) to actuator and through effector (e.g., leg) 
        the actuator creates a movement)
        * sensor (position, orientation, proximity, vision systems, inertial measurement units, and force/torque)
        * control system (processor, memory and some sort of operating system)
        * mechanical structure (e.g., frame, chassis)
    
    -- what problem robot is solving based on their operational context 
        * Markov Decision Process (MDP) for isolated actions with full environmental knowledge
        * Partially Observable Markov Decision Process (POMDP) for scenarios with incomplete information
        * game theory for cases involving other agents

    -- to actually solve it, 3-level hierarchy is used
        * task planning    - high level goal; e.g, kick a ball
        * motion planning  - step by step action to achieve above goal
        * control          - e.g., what torque to apply to actuators to complete one step in motion

    -- task planning (inc. robotic perception (sensors inputs -> representation of env (inc. robot)))
        * given current state of env, robot makes observations and takes action; by combining
        action with current state of env, we get next state of env. To keep track of observations
        and actions, we construct corresponding sensor and motion models. Since robot 
        operates in nondeterministic env, both models and states of env are all wrapped 
        with probability distrubution (you find most likely state as opposed to finding exact one)

        -- localization and mapping
        * simple motion model can be derived from (x, y, 0) of robot; to be specific, 
        (x, y, 0) -> (v, w) velocities (translational, rotational) + normal distrubution
        to account for physical uncertainties
        * for sensor model one can use landmark or range-scan model 
        * when map of env exists, localization is done using either particle filtering or Kalman filter 
        * when map doesn't exist, SLAM can be used
        * other types of perception: temperature, sound, etc; reactive agent as opposed to reasoning one

        -- ML in robotic perception
        * ML enables robot to learn sensor and motion models from data and discover a fitting
        internal representation

    -- motion planning
    
        -- configuration space, where all the points that comprise the robot are represented 
        as a single point in an abstract multidimensional space
        
        -- motion planning - finding a plan that takes a robot from one configuration to another without colliding 
        with an obstacle

            -- spaces of motion planning
            * workspace or world W, where points are points in the everyday three-dimensional world
            * space of configurations, C, where points q in C are d-dimensional, with d the robot’s 
            number of degrees of freedom, and map to sets of points A(q) in W
            * space of paths, which is a space of functions. Each point in this space maps to 
            an entire curve through C-space. This space is ∞-dimensional

            -- solutions to motion planning problem
            * visibility graphs
            * voronoi diagrams
            * cell decomposition 
            * randomized motion planning (PRM or its extension RRT or modified RRT*)

    -- control
        -- trajectory tracking control
            -- find how much torque you need and compensate for error with following control laws
            * P controller      (compensate for the error proportionally)
            * PD controller     (P + compensate more if it is increasing)
            * PID controller    (P + PD + compensate harder if you haven't made any progress in a long time)

        -- optimal control - find a sequence of actions (torques really) directly that, when executed by the robot, 
        result in state-action pairs with low cumulative cost
            * LQR
            * iterative LQR
    
    -- RL in robotics
        * model-based RL (essentially using physics-based sensor and motion models alongside RL)
        * end-to-end learning (take in sensor data and output torque values to move actuators)
        * sub-goal learning (learn sub-goals and then how to combine them)
        * transfer learning (reusing info from prev learning episodes on other tasks)
        * imitation learning (autonomous robot driving a car like a human)
        * adversarial learning (train a model to differentiate robot's learned vs human policies (the classifier) 
        and then train a new model to fool the the classifier)
